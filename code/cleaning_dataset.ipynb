{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and data\n"
      ],
      "metadata": {
        "id": "EnvY_u_eUKxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipyplot"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T14:11:36.535985Z",
          "iopub.execute_input": "2022-09-08T14:11:36.537119Z",
          "iopub.status.idle": "2022-09-08T14:11:50.246338Z",
          "shell.execute_reply.started": "2022-09-08T14:11:36.537003Z",
          "shell.execute_reply": "2022-09-08T14:11:50.245297Z"
        },
        "trusted": true,
        "id": "AFo-moCmmtnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for loading/processing the images  \n",
        "from keras.preprocessing.image import load_img \n",
        "from keras.preprocessing.image import img_to_array \n",
        "from keras.applications.vgg16 import preprocess_input \n",
        "\n",
        "# models \n",
        "from keras.applications.vgg16 import VGG16 \n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "\n",
        "# clustering and dimension reduction\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# for everything else\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from PIL import Image, ImageFilter\n",
        "import csv\n",
        "import ipyplot\n",
        "import glob\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T14:11:50.248282Z",
          "iopub.execute_input": "2022-09-08T14:11:50.248632Z",
          "iopub.status.idle": "2022-09-08T14:11:58.707891Z",
          "shell.execute_reply.started": "2022-09-08T14:11:50.248596Z",
          "shell.execute_reply": "2022-09-08T14:11:58.706632Z"
        },
        "trusted": true,
        "id": "s1szwKSNmtn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = pd.read_csv('../input/sapienza-training-camp-2022/train.csv')\n",
        "train_csv[\"path\"] = \"/content/train/train/\" + train_csv[\"category_name\"] + \"/\" + train_csv[\"file_name\"]\n",
        "\n",
        "class_name = sorted(train_csv['category_name'].unique())\n",
        "print(class_name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T14:11:58.709917Z",
          "iopub.execute_input": "2022-09-08T14:11:58.710841Z",
          "iopub.status.idle": "2022-09-08T14:11:58.743723Z",
          "shell.execute_reply.started": "2022-09-08T14:11:58.710782Z",
          "shell.execute_reply": "2022-09-08T14:11:58.742722Z"
        },
        "trusted": true,
        "id": "myOwrNkvmtn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T14:11:58.745852Z",
          "iopub.execute_input": "2022-09-08T14:11:58.746216Z",
          "iopub.status.idle": "2022-09-08T14:11:58.764692Z",
          "shell.execute_reply.started": "2022-09-08T14:11:58.746183Z",
          "shell.execute_reply": "2022-09-08T14:11:58.763803Z"
        },
        "trusted": true,
        "id": "zohY3dUVmtn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delete noisy data"
      ],
      "metadata": {
        "id": "7pDUUtNwmtn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to remove the noisy data we apply the following strategy:\n",
        "\n",
        "\n",
        "*   feature extractor using VGG16 model\n",
        "*   reduce the number of feature trough a PCA\n",
        "*   use kmeans to saparate in two classes (ship / noise)\n",
        "\n"
      ],
      "metadata": {
        "id": "UCqKpQKVVOVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_filename(dataset_class):\n",
        "    # retrieve the image name\n",
        "    input_folder = '../input/sapienza-training-camp-2022/train/train/'+dataset_class\n",
        "    images_filename = []\n",
        "    for image_file in os.listdir(input_folder):\n",
        "        images_filename.append(image_file)\n",
        "\n",
        "    return images_filename\n",
        "\n",
        "def extract_features(file, model):\n",
        "    # load the image as a 224x224 array\n",
        "    img = load_img(file, target_size=(224,224))\n",
        "    # convert from 'PIL.Image.Image' to numpy array\n",
        "    img = np.array(img)\n",
        "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
        "    reshaped_img = img.reshape(1,224,224,3) \n",
        "    # prepare image for model\n",
        "    imgx = preprocess_input(reshaped_img)\n",
        "    # get the feature vector\n",
        "    features = model.predict(imgx, use_multiprocessing=True)\n",
        "    return features\n",
        "\n",
        "def cleaning_dataset(df, dataset_class):\n",
        "    images_filename = list(df.file_name)\n",
        "    \n",
        "    # load the model first and pass as an argument\n",
        "    model = VGG16()\n",
        "    model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
        "    \n",
        "    data = {}\n",
        "    # lop through each image in the dataset\n",
        "    input_folder = '../input/sapienza-training-camp-2022/train/train/'+ dataset_class\n",
        "    for image in tqdm(images_filename):\n",
        "        feat = extract_features(os.path.join(input_folder, image), model)\n",
        "        data[image] = feat\n",
        "        \n",
        "    # get a list of the filenames\n",
        "    filenames = np.array(list(data.keys()))\n",
        "    \n",
        "    # get a list of just the features\n",
        "    feat = np.array(list(data.values()))\n",
        "    feat = feat.reshape(-1,feat.shape[-1])\n",
        "    # reduce the feeature dimension\n",
        "    n_components = 100\n",
        "    if len(feat) < 100:\n",
        "        n_components = len(feat)\n",
        "    print(\"n_componets: \", n_components)\n",
        "    pca = PCA(n_components=n_components, random_state=123)\n",
        "    pca.fit(feat)\n",
        "    x = pca.transform(feat)\n",
        "    \n",
        "    # apply kmeans to separate the image\n",
        "    kmeans = KMeans(n_clusters=2, random_state=123)\n",
        "    kmeans.fit(x)\n",
        "    \n",
        "    # holds the cluster id and the images { id: [images] }\n",
        "    groups = {}\n",
        "    for file, cluster in zip(filenames,kmeans.labels_):\n",
        "        if cluster not in groups.keys():\n",
        "            groups[cluster] = []\n",
        "            groups[cluster].append(file)\n",
        "        else:\n",
        "            groups[cluster].append(file)\n",
        "            \n",
        "    return groups\n",
        "\n",
        "def cluster_asarray(groups, dataset_class):\n",
        "\n",
        "    input_folder = '../input/sapienza-training-camp-2022/train/train/'+dataset_class\n",
        "\n",
        "    list1 = groups[1]\n",
        "    list0 = groups[0]\n",
        "    images_1 = [] \n",
        "    images_0 = [] \n",
        "\n",
        "    for image in list1:\n",
        "        image = np.array(Image.open(os.path.join(input_folder, image)))\n",
        "        image = cv2.resize(image,(244,244))\n",
        "        images_1.append(image)\n",
        "\n",
        "    for image in list0:\n",
        "        image = np.array(Image.open(os.path.join(input_folder, image)))\n",
        "        image = cv2.resize(image,(244,244))\n",
        "        images_0.append(image)\n",
        "        \n",
        "    return images_0, images_1\n",
        "\n",
        "def generation_groups(df, dataset_class):\n",
        "    ds_class = cleaning_dataset(df, dataset_class)\n",
        "    cluster0, cluster1 = cluster_asarray(ds_class, dataset_class)\n",
        "    print(\"class 0: \", len(cluster0))\n",
        "    print(\"class 1: \", len(cluster1))\n",
        "    return cluster0, cluster1, ds_class"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:34:52.682383Z",
          "iopub.execute_input": "2022-09-08T15:34:52.682847Z",
          "iopub.status.idle": "2022-09-08T15:34:52.702607Z",
          "shell.execute_reply.started": "2022-09-08T15:34:52.682810Z",
          "shell.execute_reply": "2022-09-08T15:34:52.701386Z"
        },
        "trusted": true,
        "id": "ZaJDI43cmtn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the process of cleaning"
      ],
      "metadata": {
        "id": "EdvDLT5GVzg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset0 = []\n",
        "dataset1 = []\n",
        "groups = []\n",
        "for class_ in class_name:\n",
        "    print(\"we are in class: \", class_)\n",
        "    cluster0, cluster1, ds_class = generation_groups(class_)\n",
        "    dataset0.append(cluster0)\n",
        "    dataset1.append(cluster1)\n",
        "    groups.append(ds_class)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T14:29:42.744941Z",
          "iopub.execute_input": "2022-09-08T14:29:42.745710Z",
          "iopub.status.idle": "2022-09-08T14:44:38.932364Z",
          "shell.execute_reply.started": "2022-09-08T14:29:42.745669Z",
          "shell.execute_reply": "2022-09-08T14:44:38.931206Z"
        },
        "trusted": true,
        "id": "Ijje7Eqkmtn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate the img in two right class (since kmeans doesn't define always the same class as clean or noise for all the process)"
      ],
      "metadata": {
        "id": "k4DFJQHHV4ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groups_clean  = [groups[0][0], groups[1][1], groups[2][1], groups[3][0], \n",
        "                 groups[4][0], groups[5][1], groups[6][0]]\n",
        "groups_remove = [groups[0][1], groups[1][0], groups[2][0], groups[3][1],\n",
        "                 groups[4][1], groups[5][0], groups[6][1]]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T14:57:26.955574Z",
          "iopub.execute_input": "2022-09-08T14:57:26.956714Z",
          "iopub.status.idle": "2022-09-08T14:57:26.965957Z",
          "shell.execute_reply.started": "2022-09-08T14:57:26.956661Z",
          "shell.execute_reply": "2022-09-08T14:57:26.964556Z"
        },
        "trusted": true,
        "id": "Mu496zKpmtn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_clean = [dataset0[0], dataset1[1], dataset1[2], dataset0[3],\n",
        "                 dataset0[4], dataset1[5], dataset0[6]]\n",
        "\n",
        "dataset_remove = [dataset1[0], dataset0[1], dataset0[2], dataset1[3], \n",
        "              dataset1[4], dataset0[5], dataset1[6]]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:21:18.157153Z",
          "iopub.execute_input": "2022-09-08T15:21:18.157673Z",
          "iopub.status.idle": "2022-09-08T15:21:18.164770Z",
          "shell.execute_reply.started": "2022-09-08T15:21:18.157635Z",
          "shell.execute_reply": "2022-09-08T15:21:18.163501Z"
        },
        "trusted": true,
        "id": "5850V4Pimtn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save as csv for later usage"
      ],
      "metadata": {
        "id": "AQ4fy-D1WkF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_class(groups_clean, groups_remove, category, category_id):\n",
        "    category_dict = {'file_name': groups_clean, 'category_name': category, 'category_id': category_id}\n",
        "    df_clean = pd.DataFrame.from_dict(category_dict)\n",
        "    \n",
        "    category_dict = {'file_name': groups_remove, 'category_name': category, 'category_id': category_id}\n",
        "    df_dirty = pd.DataFrame.from_dict(category_dict)\n",
        "    return df_clean, df_dirty"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:23:27.789617Z",
          "iopub.execute_input": "2022-09-08T15:23:27.790022Z",
          "iopub.status.idle": "2022-09-08T15:23:27.797547Z",
          "shell.execute_reply.started": "2022-09-08T15:23:27.789991Z",
          "shell.execute_reply": "2022-09-08T15:23:27.796224Z"
        },
        "trusted": true,
        "id": "s9k1zWWLmtn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "battleship_clean, battleship_dirty = csv_class(groups_clean[0], groups_remove[0], class_name[0], 0)\n",
        "coast_clean, coast_dirty = csv_class(groups_clean[1], groups_remove[1], class_name[1], 1)\n",
        "container_clean, container_dirty = csv_class(groups_clean[2], groups_remove[2], class_name[2], 2)\n",
        "cruise_clean, cruise_dirty = csv_class(groups_clean[3], groups_remove[3], class_name[3], 3)\n",
        "drilling_clean, drilling_dirty = csv_class(groups_clean[4], groups_remove[4], class_name[4], 4)\n",
        "motor_clean, motor_dirty = csv_class(groups_clean[5], groups_remove[5], class_name[5], 5)\n",
        "submarines_clean, submarines_dirty = csv_class(groups_clean[6], groups_remove[6], class_name[6], 6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:25:03.278031Z",
          "iopub.execute_input": "2022-09-08T15:25:03.278571Z",
          "iopub.status.idle": "2022-09-08T15:25:03.305195Z",
          "shell.execute_reply.started": "2022-09-08T15:25:03.278530Z",
          "shell.execute_reply": "2022-09-08T15:25:03.303588Z"
        },
        "trusted": true,
        "id": "sJ0i74iXmtn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final cleaning"
      ],
      "metadata": {
        "id": "4jfqboLZmtn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we can have still some dirty noise in same classes because KMeans is not a perfect classifier we re-do the process with smaller and better separable subset "
      ],
      "metadata": {
        "id": "p3FMEv0VWzFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [battleship_dirty, coast_dirty, container_dirty, cruise_dirty, drilling_dirty,\n",
        "    motor_dirty, submarines_dirty]\n",
        "\n",
        "dataset0 = []\n",
        "dataset1 = []\n",
        "groups = []\n",
        "for df, dataset_class in zip(x, class_name):\n",
        "    print(\"we are in class: \", dataset_class)\n",
        "    cluster0, cluster1, ds_class = generation_groups(df, dataset_class)\n",
        "    dataset0.append(cluster0)\n",
        "    dataset1.append(cluster1)\n",
        "    groups.append(ds_class)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:39:17.742718Z",
          "iopub.execute_input": "2022-09-08T15:39:17.743206Z",
          "iopub.status.idle": "2022-09-08T15:46:15.148939Z",
          "shell.execute_reply.started": "2022-09-08T15:39:17.743173Z",
          "shell.execute_reply": "2022-09-08T15:46:15.147547Z"
        },
        "trusted": true,
        "id": "_i59RlLfmtoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_clean = [dataset0[1], dataset0[4], dataset0[5], dataset1[6]]\n",
        "groups_clean = [groups[1][0], groups[4][0], groups[5][0], groups[6][1]]\n",
        "groups_dirty = [groups[4][1]]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:54:25.052195Z",
          "iopub.execute_input": "2022-09-08T15:54:25.052636Z",
          "iopub.status.idle": "2022-09-08T15:54:25.061479Z",
          "shell.execute_reply.started": "2022-09-08T15:54:25.052602Z",
          "shell.execute_reply": "2022-09-08T15:54:25.060267Z"
        },
        "trusted": true,
        "id": "O0p-M7uEmtoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_class(groups, category, category_id):\n",
        "    category_dict = {'file_name': groups, 'category_name': category, 'category_id': category_id}\n",
        "    df = pd.DataFrame.from_dict(category_dict)\n",
        "    return df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:56:17.182186Z",
          "iopub.execute_input": "2022-09-08T15:56:17.182663Z",
          "iopub.status.idle": "2022-09-08T15:56:17.188863Z",
          "shell.execute_reply.started": "2022-09-08T15:56:17.182624Z",
          "shell.execute_reply": "2022-09-08T15:56:17.187729Z"
        },
        "trusted": true,
        "id": "J0Eqe-ldmtoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_drilling_dirty = csv_class(groups_dirty[0], class_name[4], 4)\n",
        "cluster0, cluster1, ds_class = generation_groups(new_drilling_dirty, 'drilling-rigs')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:56:37.872419Z",
          "iopub.execute_input": "2022-09-08T15:56:37.873098Z",
          "iopub.status.idle": "2022-09-08T15:57:24.190934Z",
          "shell.execute_reply.started": "2022-09-08T15:56:37.873057Z",
          "shell.execute_reply": "2022-09-08T15:57:24.190001Z"
        },
        "trusted": true,
        "id": "D50j6AxCmtoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_drilling_clean = csv_class(ds_class[0], class_name[4], 4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T17:07:30.054898Z",
          "iopub.execute_input": "2022-09-08T17:07:30.055759Z",
          "iopub.status.idle": "2022-09-08T17:07:30.063154Z",
          "shell.execute_reply.started": "2022-09-08T17:07:30.055711Z",
          "shell.execute_reply": "2022-09-08T17:07:30.061998Z"
        },
        "trusted": true,
        "id": "vkdHZBQOmtoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save new dataframe\n",
        "new_drilling_clean = csv_class(cluster0, class_name[4], 4)\n",
        "new_coast_clean = csv_class(groups_clean[0], class_name[1], 1)\n",
        "new_drilling2_clean = csv_class(groups_clean[1], class_name[4], 4)\n",
        "new_motor_clean = csv_class(groups_clean[2], class_name[5], 5)\n",
        "new_submarines_clean = csv_class(groups_clean[3], class_name[6], 6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:59:48.824184Z",
          "iopub.execute_input": "2022-09-08T15:59:48.824766Z",
          "iopub.status.idle": "2022-09-08T15:59:48.840537Z",
          "shell.execute_reply.started": "2022-09-08T15:59:48.824726Z",
          "shell.execute_reply": "2022-09-08T15:59:48.839330Z"
        },
        "trusted": true,
        "id": "ZlNkPT0nmtoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coast_clean2 = pd.concat([coast_clean, new_coast_clean])\n",
        "drilling3 = pd.concat([drilling_clean, new_drilling_clean, new_drilling2_clean])\n",
        "motor = pd.concat([motor_clean, new_motor_clean])\n",
        "submarines = pd.concat([submarines_clean, new_submarines_clean])\n",
        "drilling3 = pd.concat([drilling_clean, new_drilling_clean, new_drilling2_clean])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T16:08:19.421018Z",
          "iopub.execute_input": "2022-09-08T16:08:19.421473Z",
          "iopub.status.idle": "2022-09-08T16:08:19.433267Z",
          "shell.execute_reply.started": "2022-09-08T16:08:19.421424Z",
          "shell.execute_reply": "2022-09-08T16:08:19.432252Z"
        },
        "trusted": true,
        "id": "cB983PvhmtoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final csv"
      ],
      "metadata": {
        "id": "KN-J5Sq9XIfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "battleship_clean.to_csv('./battleship.csv')\n",
        "coast_clean2.to_csv('./coast_guard.csv')\n",
        "container_clean.to_csv('./container.csv')\n",
        "cruise_clean.to_csv('./cruise.csv')\n",
        "drilling3.to_csv('./drilling.csv')\n",
        "motor.to_csv('./motor.csv')\n",
        "submarines.to_csv('./submarines.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T16:08:21.375022Z",
          "iopub.execute_input": "2022-09-08T16:08:21.375419Z",
          "iopub.status.idle": "2022-09-08T16:08:21.444662Z",
          "shell.execute_reply.started": "2022-09-08T16:08:21.375376Z",
          "shell.execute_reply": "2022-09-08T16:08:21.443380Z"
        },
        "trusted": true,
        "id": "bp-5mfg_mtoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipyplot.plot_images(cluster1, max_images=155)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:57:46.587724Z",
          "iopub.execute_input": "2022-09-08T15:57:46.588125Z",
          "iopub.status.idle": "2022-09-08T15:57:46.886059Z",
          "shell.execute_reply.started": "2022-09-08T15:57:46.588095Z",
          "shell.execute_reply": "2022-09-08T15:57:46.884828Z"
        },
        "trusted": true,
        "id": "0rJcjjD6mtoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_image(dataset_clean,dataset_remove, groups_clean, groups_remove, dataset_class):\n",
        "\n",
        "    input_folder = '../input/sapienza-training-camp-2022/train/train/'+dataset_class\n",
        "    output_folder = './'+dataset_class\n",
        "    \n",
        "    os.mkdir(output_folder)\n",
        "    os.mkdir(output_folder+'/clean')\n",
        "    os.mkdir(output_folder+'/noisy')\n",
        "    \n",
        "    for count, image in enumerate(dataset_clean):\n",
        "        im = Image.open(os.path.join(input_folder, image))\n",
        "        im.save(output_folder+'/clean'+'/'+dataset_class+str(count).zfill(6) +'.jpg')\n",
        "    \n",
        "    for count, image in enumerate(dataset_remove):\n",
        "        im = Image.open(os.path.join(input_folder, image))\n",
        "        im.save(output_folder+'/noisy'+'/'+dataset_class+str(count).zfill(6) +'.jpg')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-08T15:03:27.860306Z",
          "iopub.execute_input": "2022-09-08T15:03:27.860824Z",
          "iopub.status.idle": "2022-09-08T15:03:27.868885Z",
          "shell.execute_reply.started": "2022-09-08T15:03:27.860787Z",
          "shell.execute_reply": "2022-09-08T15:03:27.867680Z"
        },
        "trusted": true,
        "id": "gl1N_nMGmtoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
